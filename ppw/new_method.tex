\section{ENERGY-EFFICIENT POWER BUDGETING FOR MULTI-CORE DARK SILICON SYSTEMS}

Power budgeting, by the name, provides a power budget, which servers as a guidance and constraint for the system. The power budget in dark silicon includes the active cores distribution and their corresponding operating points. Typically, the given power budget should be conservative in order to keep the system in thermally safe state. The energy-efficient power budgeting gives a power budget not only keeps the system thermally safe, but also maximizes the energy efficiency of the system while keeping the power budget as high as possible. 

First, in Section $4.1$, we formulate the energy-efficient power budgeting problem and transforms it into an equivalent problem of minimizing the difference between the chip temperature $T_{c}$ and the target optimal temperature $T_{opt}$. Next, we show how to efficiently calculate the optimal temperature $T_{opt}$ of cores in all positions in Section $4.2$. With the $T_{opt}$, we show how to perform the proposed energy-efficient power budgeting for steady state problem in Section $4.3$, which serves as demonstration for easier understanding of the new method. In Section $4.4$, the full dynamic energy-efficient power budgeting considering transient effects is presented.

\subsection{Power budgeting by minimizing the difference of the chip temperature and the optimal temperature}
The energy-efficient dynamic power budgeting aims to find the optimal active core distribution and their corresponding DVFS stage, which can maximize the PPW of the multi-core system. While some systems may have constraints other than thermal constraint, such as total power supply limit. But the dark silicon systems are extremely thermal limited, therefore, we focus on the major problem of thermal limits, and other constraints can be added with minor modification if needed.

PPW is defined as the ratio of the total performance (MIPS) to the total power.
\begin{equation}\label{eq:ppw}
\text{PPW} = \frac{\left \| s \right \|_{1}}{\left \| P \right \|_{1}}
\end{equation}

$s$ stands for the performance of the system in MIPS, which can be converted to the operating frequency $f$ of the active cores.

For simplicity consideration, the steady state case is presented first, and the energy-efficient power budgeting problem can be formulated as the following optimization problem
\begin{equation}\label{eq:opt_ppw}
\begin{split}
\text{maximize } & \text{PPW} = \frac{\left \| f \right \|_{1}}{\left \| P \right \|_{1}}\\
\text{subject to} &\left\{
\begin{array}{lr}
\text{card}(P) = n_{a},\\
T_{c} \preceq T_{th}.\\
\end{array}
\right.
\end{split}
\end{equation}
where $T_{th} \in \mathbb{R}^{n}$ is the temperature rise threshold vector containing the maximum allowed temperature rises from the ambient temperature; card$(P)$ means the cardinality or size of the vector $P$, which is defined as the number of the nonzero components in $P$. In our case, card$(P) = n_{a}$ means there are $n_{a}$ active cores.


\begin{figure}
  \centering
  \subfigure[MIPS = 279.9, MIPS/Watt = 2.1]{
    \includegraphics[width=0.46\columnwidth]{fig/opt_tem_1.eps}\label{fig:opt_tem_1}
  }
  \subfigure[MIPS = 261.2, MIPS/Watt = 2.1]{
    \includegraphics[width=0.46\columnwidth]{fig/opt_tem_2.eps}\label{fig:opt_tem_2}
  }
  \subfigure[MIPS = 258.6, MIPS/Watt = 1.7]{
    \includegraphics[width=0.46\columnwidth]{fig/opt_tem_3.eps}\label{fig:opt_tem_3}
  }
  \subfigure[MIPS = 345.5, MIPS/Watt = 1.2]{
    \includegraphics[width=0.46\columnwidth]{fig/opt_tem_4.eps}\label{fig:opt_tem_4}
    }
  \caption{Temperature distributions of a 16-core system with 8 cores active in different power budget.}
  \label{fig:opt_tem}
\end{figure}


The optimization problem in \eqref{eq:opt_ppw} is very hard to solve, because of the high computational complexity of the problem. Therefore, we need to transform this problem into a problem with low complexity. We find out that an optimal temperature vector $T_{opt}$ exists. If a core is running at its corresponding optimal temperature, then the PPW of the core is maximized.

In Fig.~\ref{fig:opt_tem}, the temperature distributions of a $9$-core system with $5$ active cores in different power budget are shown. In Fig.~\ref{fig:opt_tem_1}, when the temperature of active cores is around \SI{45}{\degreeCelsius}, the energy efficiency of the system is maximized, due to the optimal active core distribution, the performance of the system is also optimal. In Fig.~\ref{fig:opt_tem_2}, the energy efficiency of the system is also maximized, however, because the active core distribution is not optimal, the performance of the system is less than optimal. In Fig.~\ref{fig:opt_tem_3}, the active core distribution is the same as Fig.~\ref{fig:opt_tem_1}, however, due to the random DVFS stages of active cores, the temperature of active cores is also random, the energy efficiency is not maximized. Fig.~\ref{fig:opt_tem_4} shows the temperature distribution of the system with maximized performance, as can be seen, although the active core distribution is optimal, the difference between the temperature of Fig.~\ref{fig:opt_tem_1} and Fig.~\ref{fig:opt_tem_4} is very large, and the energy efficiency of it is far less than optimal.

As can be seen in Fig.~\ref{fig:opt_tem}, the maximized PPW of the system can be obtained if all active cores are running at $T_{opt}$, no matter what active core distribution it is. However, to further maximized the performance of the system while the energy efficiency is optimal, the distribution of active cores needs to be carefully chosen.

Therefore, by minimizing the difference of the core temperature rise $T_{c}$ and the optimal temperature $T_{opt}$, the PPW of the multi-core system can be maximize. In another word, we prefer the power budget induced temperatures of all active cores to be the optimal temperature $T_{opt}$, without violating the thermal constraint.

%For the $9$-core system, we can see that there are $3$ unique core positions. We set the active core number to $1$, then we plot the PPW versus the core temperature for each of the $3$ cores in Fig. x. We can see that, as the core temperature rises, the PPW will decrease after reaching a peak value, which means a optimal temperature $T_{opt}$ exists. Also, the $T_{opt}$ for the $3$ cores in different positions varies.

We have shown that the closer the chip's temperature $T_{c}$ is to the optimal temperature $T_{opt}$, the higher the energy efficiency of the system. So instead of directly maximizing PPW, the optimization problem can be transformed to minimizing the difference between $T_{c}$ and $T_{opt}$:
\begin{equation}\label{eq:opt_topt}
\begin{split}
\text{minimize } &  \left \| T_{opt} - T_{c} \right \|_{2}\\
\text{subject to} &\left\{
\begin{array}{lr}
\text{card}(P) = n_{a},\\
T_{c} \preceq T_{th}.\\
\end{array}
\right.
\end{split}
\end{equation}

Due to the thermal impact active cores have on each other, the optimal temperature vector $T_{opt}$ is actually not a fixed-value vector, it is related to the active core number, and the active core distribution. Also, the optimal temperatures for cores in different positions of the system varies. The reason is that, for cores in position of better heat dissipation capability (such as the center of the chip), the saturation temperature which leads to maximized PPW is higher.

The optimal temperature $T_{opt}$ needed for the optimization problem in \eqref{eq:opt_topt} is dependent on many variables, which makes it impossible to efficiently calculate the $T_{opt}$ for all possible combinations, when the core number is high. Fortunately, such problem can be solved efficiently, as shown next.

\subsection{Optimal temperature calculation}
The optimal temperature $T_{opt}$ is relative to many variables, such as active core number, active core distribution and the core's position in the multi-core system. A brute force method to test all possible temperatures for all of the possible combinations, in order to find the corresponding $T_{opt}$ in which the PPW is maximized is too computationally expensive. Therefore, an efficient method to calculate the $T_{opt}$ needed to slove the optimization problem in \eqref{eq:opt_topt} is proposed in this section.

\subsubsection{Optimal temperature for single core}
Instead of calculating the optimal temperature of all cores at the same time, to simplify the problem, we calculate the optimal temperature each time for a single core.
The reason that we can calculate the optimal temperature for each core separately is that, if each of the active cores is running at maximum PPW, then the PPW of the whole system is certainly maximized.

To further simplify the problem, we can ignore the thermal impact active cores have on each other, and only consider the thermal impact of the core itself. Note that we only need to calculate the optimal temperature of cores in the unique positions of the multi-core system to obtain the optimal temperature vector for the whole system. For a $16$-core system, its $3$ unique positions are shown in Fig.x. All cores in the system can be catagorized into one of the $3$ positions.


The optimization object of maximizing PPW of a single core can be equivalently transformed to minimizing $\frac{1}{\text{PPW}}$ of it:
\begin{equation}\label{eq:min_ppw}
\text{max PPW}\Longleftrightarrow \text{min } \frac{1}{\text{PPW}},
\end{equation}

By integrating the linearized subthreshold current $I_{sub}$ in \eqref{eq:lin_leakage} into \eqref{eq:min_ppw}, we have

\begin{equation}\label{eq:1_ppw}
\begin{split}
\frac{1}{\text{PPW}} = &\frac{p_{d}+p_{s}}{f}\\
= &\frac{p_{d}+v(a_{s}(T_{i}+T_{a})+p_{0})}{f}.
%= &\frac{p_{d}+(f\cdot \frac{V_{max}-V_{th}}{f_{max}}+V_{th})(a_{s}(T_{i}+T_{a})+p_{0})}{f}
\end{split}
\end{equation}

Also from \eqref{eq:dyn_power} and \eqref{eq:f_v}, we can see that
\begin{equation}\label{eq:pd_prop_f}
p_{d} \propto f^{3}.
\end{equation}

Therefore, \eqref{eq:1_ppw} can be expressed as
\begin{equation}\label{eq:1_ppw_step2}
\begin{split}
%\frac{1}{\text{PPW}} \approx  &\frac{p_{d}+(c^{-1/3} \cdot p_{d}^{1/3}\cdot \frac{V_{max}-V_{th}}{f_{max}}+V_{th})(a_{s}(T_{i}+T_{a})+p_{0})}{c^{-1/3} \cdot p_{d}^{1/3}}\\
% =&c^{1/3}\cdot p_{d}^{2/3}+(\frac{V_{max}-V_{th}}{f_{max}}+V_{th}\cdot c^{1/3} \cdot p_{d}^{-1/3})\\
% & \cdot (a_{s}(T_{i}+T_{a})+p_{0})
\frac{1}{\text{PPW}} \approx  &\frac{p_{d}+v(a_{s}(T_{i}+T_{a})+p_{0})}{c^{-1/3} \cdot p_{d}^{1/3}}\\\
=&c^{1/3}\cdot p_{d}^{2/3}+c^{1/3} \cdot  (a_{s}(T_{i}+T_{a})+p_{0})
\end{split}
\end{equation}

We can see that in \eqref{eq:1_ppw_step2}, aside from $p_{d}$ and the core's temperature rise $T_{i}$, all other parameters are known. However, to calculate optimal temperature, we need to express $T_{i}$ using $p_{d}$, as shown next.

The optimal temperature is calculated in steady state. To calculate the steady state temperature rise of the chip, the differential term $C\frac{dT(t)}{dt}$ is neglected in 
\eqref{eq:gt}, leading to
\begin{equation}\label{eq:tc}
T_{c} = B^{T}G^{-1}BP.
\end{equation}
Let $A = B^{T}G^{-1}B \in \mathbb{R}^{m \times m}$ to simplify notation, the simplified 
\eqref{eq:tc} can be expressed as
\begin{equation}\label{sim_tc}
T_{c} = AP.
\end{equation}

Please note that, the $A$ matrix links the core temperature and the power consumption with consideration of the thermal impact of all cores and the package, which can be used to find the optimal temperature. The diagonal elements in $A$ can be seen as the corresponding cores' resistance with consideration of package, and the non-diagonal elements in the same row in $A$ serves as the other cores' impact on current core's temperature. Therefore, the diagonal elements can be extracted from $A$ to calculate the core's temperature without other cores' impact. For a specific core $i$, its temperature $T_{i}$ can be computed as:
\begin{equation}\label{eq:t_ap}
\begin{split}
T_{i}&\approx a_{ii} \cdot p_{i}\\
&=a_{ii}(p_{d}+p_{s})\\
&=a_{ii}(p_{d}+v (p_{0}+a_{s}(T_{a}+T_{i}))),
\end{split}
\end{equation}
where $a_{ii}$ stands for the current core's corresponding diagonal element from $A$, and $T_{a}$ is the ambient temperature. We can see that only variable in \eqref{eq:t_ap} is $p_{d}$, which means once $p_{d}$ is fixed, $T_{i}$ can be computed in \eqref{eq:t_ap}.



Integrating \eqref{eq:t_ap} into \eqref{eq:1_ppw_step2}, we have
\begin{equation}\label{eq:1_ppw_step3}
\begin{split}
\frac{1}{\text{PPW}} = &p_{d}^{2/3}+p_{d}^{-1/3}\cdot v(a_{s}(a_{i} \cdot p_{d}+a_{i} \cdot p_{0} \cdot v\\
 &+ v \cdot a_{i} \cdot a_{s} \cdot T_{a})/(1-v \cdot a_{i} \cdot a_{s})+p_{0})
\end{split}
\end{equation}

Note that in\eqref{eq:1_ppw_step3}, the only variable is $p_{d}$. It can also be , an inflection point for the minimum $\frac{1}{\text{PPW}}$ exists. By finding the inflection point, the minimum $\frac{1}{\text{PPW}}$ and the corresponding $p_{d}$ can be obtained. With the obtained $p_{d}$, the optimal temperature can be calculated with \eqref{eq:t_ap}.

By solving \eqref{eq:1_ppw_step3} for each of the uniquely positioned cores, the optimal temperatures vector for all cores can be formed.


\subsubsection{Optimal temperature with temperature compensation}
The above mentioned method calculated the optimal temperature without consideration of other cores' thermal impact, which could cause major error in dark silicon system, where the temperature rise caused by other cores could be higher than the temperature rise caused by the core itself. Therefore, a compensation method to modify the temperature is proposed in this section.

The basic idea of this compensation method is to add a temperature compensation parameter $\lambda$, by multiplying the core's temperature $T_{i}$ with $\lambda$, the core's temperature with other active cores' thermal impact can be obtained with approximation.

Just like optimal temperature $T_{opt}$, for different positioned cores, $\lambda$ is not the same. For core $i$, to obtain its $\lambda$, first we calculate the temperature rise $T_{i}$ from itself with \eqref{eq:t_ap}. Then we generate several random active cores distributions, note that core $i$ is included in active cores. By comparing the averaged temperature rise $T_{avg}$ of core $i$ in the random distributions with $T_{i}$, $\lambda$ can be obtained:
\begin{equation}\label{eq:lambda}
\lambda = \frac{T_{avg}-T_{i}}{T_{i}}.
\end{equation}

However, the temperature rise induced by other cores may vary dramatically, for different active core numbers and various active core distributions. If for a single core, only a single $\lambda$ is used to compensate temperature for all senerios, the error could still be large. In our work, for each core, we implement a $\lambda$ for each active core number to eliminate large error. In another word, for each core, we generate a vector, in which elements are the $\lambda$ for each active core number. By integrating all the vectors, a compensation matrix $\Lambda \in \mathbb{R}^{n \times n}$ is created. $\lambda_{ij}$ in $\Lambda$ stands for the compensation parameter for core $i$ when the active core number is $j$.


By integrating $\lambda$ into \eqref{eq:1_ppw}, we have
\begin{equation}\label{eq:c_full_1_ppw}
\begin{split}
\frac{1}{\text{PPW}}=&\frac{p_{d}+p_{s}}{f}\\
=&\frac{p_{d}+v(a_{s} \cdot ((1+\lambda)T_{i}+T_{a})+p_{0})}{p_{d}^{1/3}}\\
=&p_{d}^{2/3}+p_{d}^{-1/3}\cdot v(a_{s} ((a_{i} \cdot p_{d}+a_{i} \cdot p_{0} \cdot v\\
&+ v \cdot a_{i} \cdot a_{s} \cdot T_{a})/(1-v \cdot a_{i} \cdot a_{s})(1+\lambda)+T_{a})+p_{0}).
\end{split}
\end{equation}

By solving \eqref{eq:c_full_1_ppw} for every $\lambda$, the optimal temperature matrix can be obtained, in which $T_{ij}$ stands for the optimal temperature for core $i$ when the active core number is $j$.

\subsection{Energy-efficient power budgeting with optimal performance in steady state}
Now that the optimal temperature for all cores in each active core number is obtained, as long as the active cores' temperature is as close to the corresponding $T_{opt}$ as possible, the energy efficiency of the system is maximized, no matter what active core distribution it may be. However, it's not only energy efficiency we are seeking, the throughput of the system is also an important metric, which are affected by the active core distribution greatly in dark silicon system. Therefore, the goal of our energy-efficient power budgeting is to maximize the throughput while the energy efficiency is maximized.

In \eqref{eq:opt_topt}, we have shown that we can allocate energy-efficient power budget by making the temperature of each core as close to the optimal temperature $T_{opt}$ of itself. However, \eqref{eq:opt_topt} is still a combinational problem, which is very hard to solve. In this section, a steady state example is given to show how to efficiently find a sub-optimal solution using a greedy based method. Please note that, we present our method in steady state mainly for the purpose of clarity.

We plug \eqref{sim_tc} into the optimization problem \eqref{eq:opt_topt} and get
\begin{equation}\label{eq:sim_opt_topt}
\begin{split}
\text{minimize } &  \left \| T_{opt} - AP \right \|_{2}\\
\text{subject to} &\left\{
\begin{array}{lr}
\text{card}(P) = n_{a},\\
AP \preceq T_{th}.\\
\end{array}
\right.
\end{split}
\end{equation}

Finding the optimal solution of such optimization problem requires brute force search of all possible combinations of non-zero positions in $P$ which satisfies $\text{card}(P)=n_{a}$. The high complexity of this method makes it not suitable for multi-core system with large number of cores. It is also noticed that for such systems, finding the optimal solution is not necessary. This is due to the fact that when core number is large, each core takes relatively small area, so there exist many sub-optimal active core distributions which only have slightly larger objective value (measured by cost function) than that of the optimal solution. For example, consider a $25$-core system with $13$ cores active. The optimal solution of such system is shown in xx, and one sub-optimal solution is shown in xx. This is also verified in our experiments by comparing the optimal power budget and the sub-optimal power budget, as shown later.

For a $n$-core system with $n_{a}$ active cores, the basic idea of finding such sub-optimal solution is described as follows: we first find the optimal solution for only one active core. Next, we $fix$ the first active core position determined by the first step, and find the optimal solution of two cores, with the second active core position determined. Please note that although we say "optimal" in the second step, such sulotion is only the optimal solution with the first active core fixed at the position determined by the first step, not the true optimal solution for general two active cores. Similarly, in the $(i+1)$-th step, we look for the optimal solution for $i+1$ active cores with the position of $i$ active cores found in all previous steps remain fixed. By proceeding such strategy for $n_{a}$ steps, we can arrive at a sub-optimal solution for $n_{a}$ active cores.


To demonstrate the greedy based method in details, we begin with finding solution for one active core. The optimization problem for one active core is
\begin{equation}\label{eq:1_sim_opt_topt}
\begin{split}
\text{minimize } &  \left \| T_{opt_1} - AP \right \|_{2}\\
\text{subject to} &\left\{
\begin{array}{lr}
\text{card}(P) = 1,\\
AP \preceq T_{th}.\\
\end{array}
\right.
\end{split}
\end{equation}


We have to find a way to determine if one core is superior than the other one, measured by the cost function in \eqref{eq:1_sim_opt_topt}. For the first active core, the way to determine it is simply compare the performance of each core when the $T_{opt}$ is reached, and choose the core with maximum performance.

Then we show the general iterative steps which are used to find the distribution of $n_{a}$ active cores. Assume we have already fixed the position of $i$ active cores. The corresponding $i$ columns of $A$ are collected into
matrix $A_i \in \mathbb{R}^{i \times n}$, and power budget of these $i$
cores are expressed as vector $P_i \in \mathbb{R}^{i \times 1}$. Then,
we can form the following optimization problem to describe the power
budgeting problem with these $i$ active cores:
\begin{equation}\label{eq:temp_ss_i_pb}
  \begin{split}
    &\text{minimize~~} \|T_{opt}-A_i P_i\|_2\\
    &\text{subject to~~} A_i P_i\preceq T_{th}.
  \end{split}
\end{equation}
% The power budget $P_i$ is readily solved by changing
% \eqref{eq:temp_ss_i_pb} into the equivalent QP problem as 
% \begin{equation}\label{eq:temp_ss_i_qp}
%   \begin{split}
%     &\text{minimize~~} P_i^TA_i^TA_iP_i-2T_{th}^TA_iP_i + T_{th}^TT_{th}\\
%     &\text{subject to~~}  A_iP_i \preceq T_{th}.
%   \end{split}
% \end{equation}

In order to find the position of the $(i+1)$-th core, we subtract the
temperature rise caused by power budget of $i$ active cores from $T_{opt}$,
and obtain $T_{rm}=T_{opt}-A_iP_i$. Next, in order to find which core can complement the impact of the fixed $i$ active cores best, we compare the performance of each of the rest $n-i$ cores when $T_{rm}$ is reached, and choose the core with maximum performance.

%One example of comparing two possible active core positions (the $j$-th core and $k$-th core are took as examples) is shown in Fig.x.
%By turning on $j$-th core only, the corresponding temperature rise of the chip is $a_{j}p_{j}$, where $p_{j}$ is the $j$-th elements in $P$ which should be determined by solving \eqref{eq:1_sim_opt_topt}. Assume $p_{j}$ is correctly computed, then the $T_{j}$ component (temperature rise at position $j$) of $a_{j}p_{j}$ should be the same as the $T_{opt}$, and $T_{k}$ component of $a_{j}p_{j}$ will be lower than $T_{opt}$. Instead, by turning on the $k$-th core only, the corresponding solved power value $p_{k}$ will heat the chip to $a_{k}p_{k}$, with its $T_{j}$ component being lower than $T_{opt}$ and its $T_{k}$ component just being equal to $T_{opt}$. Between the $j$-th core and $k$-th core, we prefer to turn on the $j$-th core, 


%because its cost $\left \| T_{opt}-a_{j}p_{j} \right \|_{2}$ (length of $a_{j}p_{j}-T_{th}$ in xx) in the optimization problem \eqref{eq:1_sim_opt_topt} is smaller than the cost $\left \| T_{opt}-a_{k}p_{k} \right \|_{2}$ of turning on the $k$-th core, as observed in Fig. x. The physical meaning is: by turning on the $j$-th core, the overall system temperature is closer to $T_{opt}$. With all cores' temperature lower than $T_{opt}$, the overall system temperature of turning on the $j$-the core is higher than that of turning on the $k$-th core.

\subsection{Energy-efficient power budgeting with optimal performance considering transient effects}
The power budgeting method introduced in Section $4.3$ is for steady state condition and serves mostly for illustration of the basic idea of the dynamic power budgeting method. It may work just fine on the aspect of reliability if the computed steady state power budget is followed strictly during the power management process. However, it is frequent that chip switches between high performance mode and high energy efficiency mode, it is also possible that power management makes false decisions occasionally, the computed steady state power budget is not suitable for such senerios. Thereforce, we develop a power budgeting method by considering current transient thermal/power behaviors as follows.

From the previous illustration, we notice that the basic problem in dynamic power budgeting is to represent temperature rise $T_{c}(t+h)$ using the input power $P$ and initial temperature rise $T_{t}$. Once the formulation of $T_{c}(t+h)$ is available, we can input it into the basic optimization problem \eqref{eq:opt_topt}, and get the sub-optimal $P$ using the similar greedy based method presented in Section $4.3$.

We are able to obtain the $closed-form$ expression of $T_{c}(t+h)$ with $P$ and $T_{t}$, by taking advantage of the assumption that $P$ is constant for the future time duration $h$ in power budgeting problem, as presented next.

It is well known that thermal model as a linear system in \eqref{eq:gt} has the following solution
\begin{equation}\label{eq:ode_exp}
\begin{split}
T(t+h) &= e^{-hC^{-1}G}T(t)\\
& \quad +\int_{t}^{t+h} \! e^{-(t+h-\tau)C^{-1}G}C^{-1}BP(\tau) \, \mathrm{d}\tau.
\end{split}
\end{equation}
Because power budget is assumed to be constant for the future time
duration $h$ (i.e., from time $t$ to $t+h$), we can simplify
\eqref{eq:ode_exp} into
\begin{equation}\label{eq:ode_exp_const}
\begin{split}
T(t+h) &= e^{-hC^{-1}G}T(t)\\
& \quad +\int_{0}^{h} \! e^{-(h-\tau)C^{-1}G}C^{-1}B \, \mathrm{d}\tau P.
\end{split}
\end{equation}
Let us denote 
\begin{equation*}
M(h)=e^{-hC^{-1}G}, ~~N(h)=\int_{0}^{h} \! e^{-(h-\tau)C^{-1}G}C^{-1}B \, \mathrm{d}\tau,
\end{equation*}
then \eqref{eq:ode_exp_const} can be written as
\begin{equation}\label{eq:ode_exp_h}
T(t+h) =M(h)T(t)+N(h)P.
\end{equation}
Please note that $M(h) \in \mathbb{R}^{m\times m}$ and $N(h) \in
\mathbb{R}^{m \times n}$ are \emph{constant} matrices which
can be computed \emph{offline} for a given time step $h$. 

$M(h)T(t)$ and $N(h)P$ are the zero-input response and zero-state response of the
linear system in \eqref{eq:gt}, respectively, and there are many
easy ways to compute $M(h)$ and $N(h)$ in both frequency domain and
time domain. Here we only briefly show a time domain method presented
in~\cite{Han:JLPE'07}. 
Let us denote $M(h)=[M_1, M_2, \ldots, M_m]$, $N(h)=[N_1, N_2, \ldots, N_n]$,
$T(0)=[T_1, T_2, \ldots, T_m]^T$, and $P=[p_1, p_2, \ldots, p_n]^T$,
where $M_i$ and $N_i$ represent the $i$-th columns of $M(h)$ and $N(h)$,
$T_i$ and $p_i$ represent the $i$-th elements of $T(0)$ and $P$,
respectively. With linear system theory, we have $M_i=T(h)$, if we let $P=[0,0,\ldots,0]^{T}$, $T_i=1$, and
$T_j=0$ for all $j\neq i$. As a result, we can get the $i$-th column of
$M(h)$ by computing $T(h)$ using standard numerical integration of \eqref{eq:gt} with only the $i$-th
element of initial state $T(0)$ set to be one. Similarly, we have
$N_i=T(h)$, if we let $T(0)=[0,0,\ldots,0]^T$, $p_i=1$, and $p_j=0$ for all $j\neq
i$. In another word, the $i$-th column of
$N(h)$ can be obtained by computing $T(h)$ using numerical integration of
\eqref{eq:gt} with only the $i$-th
element of power $P$ set to be one.

Finally, we are able to express $T_c(t+h)$ using $P$ and $T(t)$ as
\begin{equation}
T_c(t+h) = B^{T}T(t+h)= B^{T}M(h)T(t)+B^{T}N(h)P.
\end{equation}
The cost function of the steady state power budgeting problem in
\eqref{eq:opt_topt} will be changed by using the new $T_c(t+h)$ for
transient case as

\begin{equation}\label{eq:cost_trans}
\|T_{opt} - B^{T}M(h)T(t) - B^{T}N(h)P \|_2.
\end{equation}
In order to simplify notation, we denote a new vector  
\begin{equation}
\bar{T}_{opt}=T_{opt} - B^{T}M(h)T(t),
\end{equation}
where $\bar{T}_{opt}$ has similar meaning of
$T_{opt}$ in steady state case, and it also accounts for the transient
thermal effects, i.e., current temperature's impact on power
budget. Also, we denote a new matrix 

\begin{equation}
\bar{A} = B^{T}N(h), 
\end{equation}
which works similarly as matrix $A$ in steady
state case, but accounts for transient thermal effect. The power
budgeting optimization problem for transient case is updated as 




\begin{equation}\label{eq:temp_ts_opt}
\begin{split}
\text{minimize } &  \left \| \bar{T}_{opt}-\bar{A}P \right \|_{2}\\
\text{subject to} &\left\{
\begin{array}{lr}
\text{card}(P) = n_{a},\\
\bar{A}P \preceq \bar{T}_{th}.\\
\end{array}
\right.
\end{split}
\end{equation}
Now dynamic power budgeting can be
applied by following the steps in steady state power budgeting presented in
Section $4.3$, just with \eqref{eq:sim_opt_topt} replaced
by \eqref{eq:temp_ts_opt}.