\section{ENERGY-EFFICIENT POWER BUDGETING FOR MULTI-CORE DARK SILICON SYSTEMS}

Power budgeting, by the name, provides a power budget, which servers as a guidance and constraint for the system. The power budget in dark silicon includes the active cores distribution and their corresponding DVFS stages. Typically, the given power budget should be conservative in order to keep the system in thermally safe state. The energy-efficient power budgeting gives a power budget not only keeps the system thermally safe, but also maximizes the energy efficiency of the system while keeping the power budget as high as possible.

%First, in Section $4.1$, we formulate the energy-efficient power budgeting problem and transforms it into an equivalent problem of minimizing the difference between the chip temperature $T_{c}$ and the target optimal temperature $T_{opt}$. Next, we show how to efficiently calculate the optimal temperature $T_{opt}$ of cores in all positions in Section $4.2$. With the $T_{opt}$, we show how to perform the proposed energy-efficient power budgeting for steady state problem in Section $4.3$, which serves as demonstration for easier understanding of the new method. In Section $4.4$, the full dynamic energy-efficient power budgeting considering transient effects is presented.



\subsection{Overview of energy efficiency}
Before proceeding to the energy-efficient power budgeting problem, it will be worthwhile to examine the characteristics of energy efficiency of multi-core systems.

We first use Monte Carlo method, by fixing active core number and distribution, only changing the DVFS stages of active cores, we obtain the optimal DVFS stages of each active cores that leads to maximum energy efficiency for several fixed active core distributions. The Monte Carlo simulation number for each fixed active core distribution is $10000$. The corresponding temperature distribution is plotted in Fig.~\ref{fig:opt_tem}, in which the temperature distributions of a $9$-core system with $5$ active cores are shown. 

As can be seen, the optimal energy efficiency of both Fig.~\ref{fig:opt_tem_1} and Fig.~\ref{fig:opt_tem_2} are relatively the same, although the active core distribution is not the same for them, which means that the active core distribution that corresponds to optimal energy efficiency is not unique. However, for different active core distributions, the throughput while in optimal energy efficiency are not the same, and our goal is to choose the active core distribution that can provide the maximum throughput while in optimal energy efficiency.


%Therefore, the energy-efficient dynamic power budgeting can be divided into two steps, first is to maximize the energy efficiency of the system, the next is to optimize the throughput of the system while in maximum energy efficiency.
Fig.~\ref{fig:f_ppw} shows the simulation plot of PPW against the core frequency of a single core processor. As Fig.~\ref{fig:f_ppw} shows, as the frequency of the core increases from minimum to maximum, the PPW metric will first increase along to a maximum value, then decreases to a minimum value. It means that there is an optimal frequency which leads to maximum energy frequency, and the closer the current frequency is to the optimal frequency, the higher the energy efficiency.


\begin{figure}
  \centering
  \subfigure[MIPS = 246.3, MIPS/Watt = 2.6]{
    \includegraphics[width=0.46\columnwidth]{fig/opt_tem_1.eps}\label{fig:opt_tem_1}
  }
  \subfigure[MIPS = 215.6, MIPS/Watt = 2.6]{
    \includegraphics[width=0.46\columnwidth]{fig/opt_tem_2.eps}\label{fig:opt_tem_2}
  }
  % \subfigure[MIPS = 258.6, MIPS/Watt = 1.7]{
  %   \includegraphics[width=0.46\columnwidth]{fig/opt_tem_3.eps}\label{fig:opt_tem_3}
  % }
  % \subfigure[MIPS = 345.5, MIPS/Watt = 1.2]{
  %   \includegraphics[width=0.46\columnwidth]{fig/opt_tem_4.eps}\label{fig:opt_tem_4}
  %   }
  \caption{Temperature distributions of a 9-core system with 5 cores active in maximum energy efficiency.}
  \label{fig:opt_tem}
\end{figure}




% \begin{figure}
% \centering
% \includegraphics[width=0.8\linewidth]{fig/f_ppw.eps}
% \caption{Core frequency/PPW curve}
% \label{fig:f_ppw}
% \end{figure}

\subsection{Maximizing the energy efficiency of multi-core system}
The energy-efficient dynamic power budgeting aims to find the optimal active core distributions and their corresponding DVFS stages, which can maximize the PPW of the multi-core system. While some systems may have constraints other than thermal constraint, such as total power supply limit. But the dark silicon systems are extremely thermal limited, therefore, we focus on the major problem of thermal limits, and other constraints can be added with minor modification if needed.

PPW is defined as the ratio of the total performance (MIPS) to the total power.
\begin{equation}\label{eq:ppw}
\text{PPW} = \frac{\left \| s \right \|_{1}}{\left \| P \right \|_{1}}
\end{equation}

$s$ stands for the performance of the system in MIPS, which can be converted to the operating frequency $f$ of the active cores.

For simplicity consideration, the steady state case is presented first, and the energy-efficient power budgeting problem can be formulated as the following optimization problem
\begin{equation}\label{eq:opt_ppw}
\begin{split}
\text{maximize } & \text{PPW} = \frac{\left \| f \right \|_{1}}{\left \| P \right \|_{1}}\\
\text{subject to} &\left\{
\begin{array}{lr}
\text{card}(P) = n_{a},\\
T_{c} \preceq T_{th}.\\
\end{array}
\right.
\end{split}
\end{equation}
where $T_{th} \in \mathbb{R}^{n}$ is the temperature rise threshold vector containing the maximum allowed temperature rises from the ambient temperature; card$(P)$ means the cardinality or size of the vector $P$, which is defined as the number of the nonzero components in $P$. In our case, card$(P) = n_{a}$ means there are $n_{a}$ active cores.

The optimization problem in \eqref{eq:opt_ppw} is very hard to solve, because of the high computational complexity of the problem. Therefore, we need to transform this problem into a problem with low complexity.

If the frequency $f$ that corresponds to the maximum PPW can be obtained, we can set it to be $f_{opt}$, then the target of the optimization problem can be transformed into $\text{minimize }   \left \| f_{opt} - f \right \|_{2}$. Which means, the closer the chip's frequency $f$ is to the optimal throughput $f_{opt}$, the higher the energy efficiency of the system. Considering $f_{opt}$ is hard to obtain, also, $T_{c}$ can be uniquely calculated for a specific $f$ with \eqref{eq:gt}. The maximum PPW can be obtained if all cores are running at $T_{opt}$, which is the temperature when the frequency of all cores are $f_{opt}$. Therefore, the closer the chip's temperature $T_{c}$ is to the optimal temperature $T_{opt}$, the higher the energy efficiency of the system. So instead of directly maximizing PPW, the optimization problem can be transformed to minimizing the difference between $T_{c}$ and $T_{opt}$:

\begin{equation}\label{eq:opt_topt}
\begin{split}
\text{minimize } &  \left \| T_{opt} - T_{c} \right \|_{2}\\
\text{subject to} &\left\{
\begin{array}{lr}
\text{card}(P) = n_{a},\\
T_{c} \preceq T_{th}.\\
\end{array}
\right.
\end{split}
\end{equation}

The optimal temperature $T_{opt}$ needed for the optimization problem in \eqref{eq:opt_topt} is dependent on many variables, which makes it impossible to efficiently calculate the $T_{opt}$ for all possible combinations, when the core number is high. Fortunately, such problem can be solved efficiently, as shown next.

\subsection{Optimal temperature calculation}
Due to the thermal impact active cores have on each other, the optimal temperature $T_{opt}$ is relative to many variables, such as active core number, active core distribution and the core's position in the multi-core system. A brute force method to test all possible temperatures for all of the possible combinations, in order to find the corresponding $T_{opt}$ in which the PPW is maximized is too computationally expensive. Therefore, an efficient method to calculate the $T_{opt}$ needed to solve the optimization problem in \eqref{eq:opt_topt} is proposed in this section.

Instead of calculating the $T_{opt}$ for each scenario, the basic idea of the method is to obtain a general optimal temperature vector $\bar{T}_{opt}$ for each of the active core number, no matter what active core distribution it is, as long as the $\bar{T}_{opt}$ is followed for each active core, the energy efficiency is maximized.

\subsubsection{Optimal temperature for isolated core}

\begin{figure}
\centering
\includegraphics[width=0.46\linewidth]{fig/unique_position.eps}
\caption{$3$ unique positions for a $16$-core system.}
\label{fig:unique_position}
\end{figure}

Calculating the optimal temperature for the whole system requires consideration of the thermal impact that cores have on each other, which greatly complicates the problem when the core number and active core number is large. 
If we isolate the cores, the problem can be simplified. Note that, for a $16$-core system, there are only $3$ unique positions which are shown in Fig.~\ref{fig:unique_position}. All cores in the system can be categorized into one of the $3$ positions, we only need to calculate the optimal temperature of one of the cores in the unique positions of the multi-core system to obtain the optimal temperature vector for the whole system, which can also reduce the computation time.

Therefore, we first consider calculating $\bar{T}_{opt}$ for isolated cores, which serves as an simple example for optimal temperature calculation.

%The reason is that, if each of the active cores is running at maximum PPW, then the PPW of the whole system is certainly maximized.

%To further simplify the problem, we can ignore the thermal impact active cores have on each other, and only consider the thermal impact of the core itself. Note that we only need to calculate the optimal temperature of cores in the unique positions of the multi-core system to obtain the optimal temperature vector for the whole system. 


The optimization object of maximizing PPW of a single core can be expressed as:
%equivalently transformed to minimizing $\frac{1}{\text{PPW}}$ of it:
% \begin{equation}\label{eq:min_ppw}
% \text{max PPW}\Longleftrightarrow \text{min } \frac{1}{\text{PPW}},
% \end{equation}
\begin{equation}\label{eq:min_ppw}
\text{PPW}=\frac{f}{p_{d}+p_{s}},
\end{equation}


By integrating the linearized subthreshold current $I_{sub}$ in \eqref{eq:lin_leakage} into \eqref{eq:min_ppw}, we have

\begin{equation}\label{eq:1_ppw}
\text{PPW} = \frac{f}{p_{d}+V_{dd}(a_{s}T+p_{0})}.
\end{equation}

% \begin{equation}\label{eq:1_ppw}
% \begin{split}
% \frac{1}{\text{PPW}} = &\frac{p_{d}+p_{s}}{f}\\
% = &\frac{p_{d}+V_{dd}(a_{s}T+p_{0})}{f}.
% \end{equation}


% Also from \eqref{eq:dyn_power} and \eqref{eq:f_v}, we can see that
% \begin{equation}\label{eq:pd_prop_f}
% p_{d} \propto f^{3}.
% \end{equation}

% Therefore, \eqref{eq:1_ppw} can be expressed as
% \begin{equation}\label{eq:1_ppw_step2}
% \begin{split}
% %\frac{1}{\text{PPW}} \approx  &\frac{p_{d}+(c^{-1/3} \cdot p_{d}^{1/3}\cdot \frac{V_{max}-V_{th}}{f_{max}}+V_{th})(a_{s}(T_{i}+T_{a})+p_{0})}{c^{-1/3} \cdot p_{d}^{1/3}}\\
% % =&c^{1/3}\cdot p_{d}^{2/3}+(\frac{V_{max}-V_{th}}{f_{max}}+V_{th}\cdot c^{1/3} \cdot p_{d}^{-1/3})\\
% % & \cdot (a_{s}(T_{i}+T_{a})+p_{0})
% \frac{1}{\text{PPW}} \approx  &\frac{p_{d}+v(a_{s}(T_{i}+T_{a})+p_{0})}{c^{-1/3} \cdot p_{d}^{1/3}}\\\
% =&c^{1/3}\cdot p_{d}^{2/3}+c^{1/3} \cdot  p^{-1/3}\cdot v(a_{s}(T_{i}+T_{a})+p_{0})
% \end{split}
% \end{equation}

%We can see that in \eqref{eq:1_ppw_step2}, there are $3$ parameters that are not fixed, $p_{d}$, the core's temperature rise $T_{i}$ and $v$, all other parameters are known. However, to calculate optimal temperature, we need to minimize the number of the variables. Therefore, we will demonstrate how to express $T_{i}$ and $v$ using $p_{d}$ next.

Note that, for a specific core $i$, $T$ in \eqref{eq:1_ppw} is composed of the core's temperature rise $T_{i}$ and the ambient temperature $T_{a}$. To calculate $T_{i}$ for the isolated core $i$, we need to extract relevant information from the $G$ matrix. Because the optimal temperature is calculated in steady state, to calculate the steady state temperature rise $T_{c}$ of the chip, the differential term $C\frac{dT(t)}{dt}$ is neglected in 
\eqref{eq:gt}, leading to
\begin{equation}\label{eq:tc}
T_{c} = B^{T}G^{-1}BP.
\end{equation}
Let $A = B^{T}G^{-1}B \in \mathbb{R}^{m \times m}$ to simplify notation, the simplified 
\eqref{eq:tc} can be expressed as
\begin{equation}\label{sim_tc}
T_{c} = AP.
\end{equation}

\begin{figure}
\centering
\includegraphics[width=0.7\linewidth]{fig/ap.eps}
\caption{The diagram of computing $T_{c}$.}
\label{fig:apt}
\end{figure}


Please note that, as Fig.~\ref{fig:apt} shows, the $A$ matrix links the core temperature and the power consumption with consideration of the thermal impact of all cores and the package, which can be used to find the optimal temperature. The diagonal elements in $A$ can be seen as the corresponding cores' resistance with consideration of package, and the non-diagonal elements in the same row in $A$ serves as the other cores' impact on current core's temperature. Therefore, the diagonal elements can be extracted from $A$ to calculate the isolated core's temperature. For a specific core $i$, its temperature rise $T_{i}$ can be computed as:
\begin{equation}\label{eq:t_ap}
\begin{split}
T_{i}&\approx a_{ii} \cdot p_{i}\\
&=a_{ii}(p_{d}+p_{s})\\
&=a_{ii}(p_{d}+V_{dd} (p_{0}+a_{s}T)),
\end{split}
\end{equation}
where $a_{ii}$ stands for the current core's corresponding diagonal element from $A$.

We can see that variables in \eqref{eq:1_ppw} and \eqref{eq:t_ap} are $p_{d}$, $f$ and $v$. Also, $f$ and $v$ can be expressed with $p_{d}$ from \eqref{eq:dyn_power} and \eqref{eq:f_v}, then \eqref{eq:1_ppw} with the only variable $p_{d}$ can be expressed as:

% \begin{equation}\label{eq:v_pd}
% \begin{split}
% v = &f\cdot \frac{V_{max}-V_{th}}{f_{max}}+V_{th},\\
% =&c^{-1/3} \cdot p_{d}^{1/3}\cdot \frac{V_{max}-V_{th}}{f_{max}}+V_{th}.
% \end{split}
% \end{equation}

% Integrating \eqref{eq:t_ap} and \eqref{eq:v_pd} into \eqref{eq:1_ppw_step2}, we have
% \begin{equation}\label{eq:1_ppw_detail}
% \begin{split}
% \frac{1}{\text{PPW}} = &p_{d}^{2/3}+p_{d}^{-1/3}\cdot v(a_{s}(a_{i} \cdot p_{d}+a_{i} \cdot p_{0} \cdot v\\
%  &+ v \cdot a_{i} \cdot a_{s} \cdot T_{a})/(1-v \cdot a_{i} \cdot a_{s})+p_{0})
% \end{split}
% \end{equation}
\begin{equation}\label{eq:1_ppw_2}
\text{PPW} = \frac{\epsilon_{1}-\epsilon_{2}p_{d}^{1/3}}{\epsilon_{3}+p_{d}^{2/3}},
\end{equation}
where $\epsilon_{1}$, $\epsilon_{2}$ and $\epsilon_{1}$ stand for different positive constant. We can prove that an inflection point for the maximum $\text{PPW}$ exists with a corresponding positive $p_{d}$. With the obtained $p_{d}$, the optimal temperature can be calculated with \eqref{eq:t_ap}.

By solving \eqref{eq:1_ppw_2} for each of the uniquely positioned cores, the optimal temperatures vector for all cores can be formed.

\begin{table*}
  \caption{The optimal temperature error induce with and without temperature compensation parameter. The fixed core is the $1^{st}$ core, for each active core number, $50$ random active core distributions are generated.}
  \label{tab:compensation}
  \centering
  \begin{tabular}{c|c||p{1cm}<{\centering}|p{1cm}<{\centering}||p{1cm}<{\centering}|p{1cm}<{\centering}}
    \hline
    Core & Active     & \multicolumn{2}{c||}{$T_{err}$($^{\circ}$C)  with $\lambda$}  & \multicolumn{2}{c}{$T_{err}$($^{\circ}$C) without $\lambda$}\\
\cline{3-6}
    \#       &   \#       &  Avg    & Max &  Avg  &  Max  \\
     \hline
\hline
  \multirow{3}{*}{9} &      2       &   1.1  &   1.9 &2.1&4.0\\
             &      4       &    1.3    &   2.7  &7.0&11.7 \\
             &      7       &   1.2     &   2.2   &13.7&16.1\\
     \hline
   \multirow{3}{*}{16} &      3        &   0.3 &   0.7   &1.5 &2.2 \\   
             &      8       &    0.5     &  1.2  &7.2 &8.3   \\
             &      13     &     0.4    &   1.2  &12.9 &13.7 \\
     \hline
  \multirow{3}{*}{25} &      5       &    0.4 & 1.1 & 3.2 &  4.2   \\ 
              &     12      &    0.5     &    1.4   &  8.7 & 9.9 \\
              &     20      &    0.4     &    1.1   & 13.5 & 14.1 \\ 
     \hline
  \multirow{3}{*}{36}  &     8        &    0.4  &    1.1 & 4.1 & 5.6\\
              &     18      &   0.5      &   1.6  & 10.0 & 11.4  \\
              &     28      &    0.4     &   0.9 & 14.4 & 15.2\\
     \hline
  \multirow{3}{*}{64}  &     12      &   0.4  &   1.2  & 3.8 &4.9 \\
              &     32      &    0.5     &     1.6   & 9.6 & 10.6   \\
              &     52      &     0.4   &     1.0   & 15.9 & 16.5\\
 \hline 
\multirow{3}{*}{100}  & 16 & 	 0.5&	1.1& 3.3 &  4.3\\
                      & 52 &	 0.7&	1.7& 11.4 & 13.0\\
                      & 76 &	 0.5&	1.8& 16.6 & 17.6\\
\hline
\end{tabular}
\end{table*}


\subsubsection{Optimal temperature with temperature compensation}
The above mentioned method calculated the optimal temperature without consideration of other cores' thermal impact, which could cause major error in dark silicon system, where the temperature rise caused by other cores could make up of a considerable part of the whole temperature rise. Therefore, a compensation method to modify the isolated core's temperature rise $T_{i}$ is proposed in this section.

The basic idea of this compensation method is to add a temperature compensation parameter $\lambda$, by multiplying the core's temperature $T_{i}$ with $\lambda$, the core's temperature with other active cores' thermal impact can be obtained with approximation without complicating the problem.

Just like optimal temperature $T_{opt}$, for different positioned cores, $\lambda$ is not the same. For core $i$, to obtain its $\lambda$, first we calculate the temperature rise $T_{i}$ from itself with \eqref{eq:t_ap}. Then we generate several random active cores distributions, note that core $i$ is included in active cores. By comparing the averaged temperature rise $T_{avg}$ of core $i$ in the random distributions with $T_{i}$, $\lambda$ can be obtained:
\begin{equation}\label{eq:lambda}
\lambda = \frac{T_{avg}-T_{i}}{T_{i}}.
\end{equation}

However, the temperature rise induced by other cores may vary dramatically, for different active core numbers and various active core distributions. If for a single core, only a single $\lambda$ is used to compensate temperature for all senerios, the error could still be large. In our work, for each core, we implement a $\lambda$ for each active core number to eliminate large error. In another word, for each core, we generate a vector, in which elements are the $\lambda$ for each active core number. By integrating all the vectors, a compensation matrix $\Lambda \in \mathbb{R}^{n \times n}$ is created. $\lambda_{ij}$ in $\Lambda$ stands for the compensation parameter for core $i$ when the active core number is $j$.

By integrating $\lambda$ into \eqref{eq:1_ppw}, we have

\begin{equation}\label{eq:c_full_1_ppw}
\text{PPW}=\frac{f}{p_{d}+V_{dd}(a_{s}((1+\lambda)T_{i}+T_{a})+p_{0})},
\end{equation}

which can be transformed into an expression with the only variable being $p_{d}$ like \eqref{eq:1_ppw_2}. By solving \eqref{eq:c_full_1_ppw} for every $\lambda$, the optimal temperature matrix can be obtained, in which $T_{ij}$ stands for the optimal temperature for core $i$ when the active core number is $j$.

In order to test the effectiveness of the temperature compensation parameter, for example, we first choose a $9$-core system with $4$ active core, the optimal temperature for a specified core with temperature compensation parameter can be computed in \eqref{eq:c_full_1_ppw} and \eqref{eq:t_ap}. Then, we randomly generate several $4$ active core distributions of a $9$-core system, and compute the real optimal temperature of each of the distribution. Note that the specified core in the previous step is included in the active cores. By comparing the difference of the optimal temperature, the effective of the temperature compensation parameter can be verified.

In addition to the case shown above, we tested many other systems with different number of cores and active cores. The results are collected in Table~\ref{tab:compensation}.

% \begin{equation}\label{eq:c_full_1_ppw}
% \begin{split}
% \frac{1}{\text{PPW}}=&\frac{p_{d}+p_{s}}{f}\\
% =&\frac{p_{d}+v(a_{s} \cdot ((1+\lambda)T_{i}+T_{a})+p_{0})}{p_{d}^{1/3}}\\
% =&p_{d}^{2/3}+p_{d}^{-1/3}\cdot v(a_{s} ((a_{i} \cdot p_{d}+a_{i} \cdot p_{0} \cdot v\\
% &+ v \cdot a_{i} \cdot a_{s} \cdot T_{a})/(1-v \cdot a_{i} \cdot a_{s})(1+\lambda)+T_{a})+p_{0}).
% \end{split}
% \end{equation}

\subsection{Energy-efficient power budgeting with optimal performance in steady state}
Now that the optimal temperature for all cores in each active core number is obtained, as long as the active cores' temperature is as close to the corresponding $T_{opt}$ as possible, the energy efficiency of the system is maximized, no matter what active core distribution it may be. However, it's not only energy efficiency we are seeking, the throughput of the system is also an important metric, which are affected by the active core distribution greatly in dark silicon system. Therefore, the goal of our energy-efficient power budgeting is to maximize the throughput while the energy efficiency is maximized.

In \eqref{eq:opt_topt}, we have shown that we can allocate energy-efficient power budget by making the temperature of each core as close to the optimal temperature $T_{opt}$ of itself. However, \eqref{eq:opt_topt} is still a combinational problem, which is very hard to solve. In this section, a steady state example is given to show how to efficiently find a sub-optimal solution using a greedy based method. Please note that, we present our method in steady state mainly for the purpose of clarity.

We plug \eqref{sim_tc} into the optimization problem \eqref{eq:opt_topt} and get
\begin{equation}\label{eq:sim_opt_topt}
\begin{split}
\text{minimize } &  \left \| T_{opt} - AP \right \|_{2}\\
\text{subject to} &\left\{
\begin{array}{lr}
\text{card}(P) = n_{a},\\
AP \preceq T_{th}.\\
\end{array}
\right.
\end{split}
\end{equation}

Finding the optimal solution of such optimization problem requires brute force search of all possible combinations of non-zero positions in $P$ which satisfies $\text{card}(P)=n_{a}$. The high complexity of this method makes it not suitable for multi-core system with large number of cores. It is also noticed that for such systems, finding the optimal solution is not necessary. This is due to the fact that when core number is large, each core takes relatively small area, so there exist many sub-optimal active core distributions which only have slightly larger objective value (measured by cost function) than that of the optimal solution. For example, consider a $25$-core system with $13$ cores active. The optimal solution of such system is shown in xx, and one sub-optimal solution is shown in xx. This is also verified in our experiments by comparing the optimal power budget and the sub-optimal power budget, as shown later.

For a $n$-core system with $n_{a}$ active cores, the basic idea of finding such sub-optimal solution is described as follows: we first find the optimal solution for only one active core. Next, we $fix$ the first active core position determined by the first step, and find the optimal solution of two cores, with the second active core position determined. Please note that although we say "optimal" in the second step, such solution is only the optimal solution with the first active core fixed at the position determined by the first step, not the true optimal solution for general two active cores. Similarly, in the $(i+1)$-th step, we look for the optimal solution for $i+1$ active cores with the position of $i$ active cores found in all previous steps remain fixed. By proceeding such strategy for $n_{a}$ steps, we can arrive at a sub-optimal solution for $n_{a}$ active cores.


To demonstrate the greedy based method in details, we begin with finding solution for one active core. The optimization problem for one active core is
\begin{equation}\label{eq:1_sim_opt_topt}
\begin{split}
\text{minimize } &  \left \| T_{opt_1} - AP \right \|_{2}\\
\text{subject to} &\left\{
\begin{array}{lr}
\text{card}(P) = 1,\\
AP \preceq T_{th}.\\
\end{array}
\right.
\end{split}
\end{equation}


We have to find a way to determine if one core is superior than the other one, measured by the cost function in \eqref{eq:1_sim_opt_topt}. For the first active core, the way to determine it is simply compare the performance of each core when the $T_{opt}$ is reached, and choose the core with maximum performance.

Then we show the general iterative steps which are used to find the distribution of $n_{a}$ active cores. Assume we have already fixed the position of $i$ active cores. The corresponding $i$ columns of $A$ are collected into
matrix $A_i \in \mathbb{R}^{i \times n}$, and power budget of these $i$
cores are expressed as vector $P_i \in \mathbb{R}^{i \times 1}$. Then,
we can form the following optimization problem to describe the power
budgeting problem with these $i$ active cores:
\begin{equation}\label{eq:temp_ss_i_pb}
  \begin{split}
    &\text{minimize~~} \|T_{opt}-A_i P_i\|_2\\
    &\text{subject to~~} A_i P_i\preceq T_{th}.
  \end{split}
\end{equation}
% The power budget $P_i$ is readily solved by changing
% \eqref{eq:temp_ss_i_pb} into the equivalent QP problem as 
% \begin{equation}\label{eq:temp_ss_i_qp}
%   \begin{split}
%     &\text{minimize~~} P_i^TA_i^TA_iP_i-2T_{th}^TA_iP_i + T_{th}^TT_{th}\\
%     &\text{subject to~~}  A_iP_i \preceq T_{th}.
%   \end{split}
% \end{equation}

\begin{figure*}[htb]
\centering
\subfigure[Previous temperature is below $T_{opt}$.]{
\begin{minipage}{.3\linewidth}
\centering
\includegraphics[width=\textwidth]{fig/ppw_boost_1.eps}\label{fig:ppw_boost_1}
\end{minipage}
}
\subfigure[Previous temperature is above $T_{opt}$.]{
\begin{minipage}{.3\linewidth}
\centering
\includegraphics[width=\textwidth]{fig/ppw_boost_2.eps}\label{fig:ppw_boost_2}
\end{minipage}
}
\subfigure[Previous temperature is $T_{opt}$.]{
\begin{minipage}{.3\linewidth}
\centering
\includegraphics[width=\textwidth]{fig/ppw_boost_3.eps}\label{fig:ppw_boost_3}
\end{minipage}
}
\caption{Demonstration of changing temperature and the corresponding PPW. $f_{1}>f_{2}>f_{3}$, and $f_{2}$ can lead to $T_{opt}$ in $T(t+h)$.}
\label{fig:ppw_boost}
\end{figure*}

In order to find the position of the $(i+1)$-th core, we subtract the
temperature rise caused by power budget of $i$ active cores from $T_{opt}$,
and obtain $T_{rm}=T_{opt}-A_iP_i$. Next, in order to find which core can complement the impact of the fixed $i$ active cores best, we compare the performance of each of the rest $n-i$ cores when $T_{rm}$ is reached, and choose the core with maximum performance.

%One example of comparing two possible active core positions (the $j$-th core and $k$-th core are took as examples) is shown in Fig.x.
%By turning on $j$-th core only, the corresponding temperature rise of the chip is $a_{j}p_{j}$, where $p_{j}$ is the $j$-th elements in $P$ which should be determined by solving \eqref{eq:1_sim_opt_topt}. Assume $p_{j}$ is correctly computed, then the $T_{j}$ component (temperature rise at position $j$) of $a_{j}p_{j}$ should be the same as the $T_{opt}$, and $T_{k}$ component of $a_{j}p_{j}$ will be lower than $T_{opt}$. Instead, by turning on the $k$-th core only, the corresponding solved power value $p_{k}$ will heat the chip to $a_{k}p_{k}$, with its $T_{j}$ component being lower than $T_{opt}$ and its $T_{k}$ component just being equal to $T_{opt}$. Between the $j$-th core and $k$-th core, we prefer to turn on the $j$-th core, 


%because its cost $\left \| T_{opt}-a_{j}p_{j} \right \|_{2}$ (length of $a_{j}p_{j}-T_{th}$ in xx) in the optimization problem \eqref{eq:1_sim_opt_topt} is smaller than the cost $\left \| T_{opt}-a_{k}p_{k} \right \|_{2}$ of turning on the $k$-th core, as observed in Fig. x. The physical meaning is: by turning on the $j$-th core, the overall system temperature is closer to $T_{opt}$. With all cores' temperature lower than $T_{opt}$, the overall system temperature of turning on the $j$-the core is higher than that of turning on the $k$-th core.




\subsection{Energy-efficient power budgeting with optimal performance considering transient effects}
The power budgeting method introduced in Section $4.3$ is for steady state condition and serves mostly for illustration of the basic idea of the dynamic power budgeting method. It may work just fine on the aspect of reliability if the computed steady state power budget is followed strictly during the power management process. However, it is frequent that chip switches between high performance mode and high energy efficiency mode, it is also possible that power management makes false decisions occasionally, the computed steady state power budget is not suitable for such scenarios. Therefore, we develop a power budgeting method by considering previous transient thermal/power behaviors as follows.

Before we demonstrate any details, it's necessary to examine the PPW metric in transient state.
There are generally $3$ cases in transient state, the previous temperature is below $T_{opt}$, or above $T_{opt}$, or just $T_{opt}$. For each case, based on the target temperature, $3$ scenarios can be classified, target temperature above $T_{opt}$, or below $T_{opt}$ or just $T_{opt}$. We assume the operating frequency in one control cycle is fixed, therefore, the $3$ scenarios for each case can be viewed as with different operating frequencies, which are $f_{1}>f_{2}>f_{3}$, and by applying $f_{2}$, $T_{opt}$ can be reached in $T(t+h)$, where $h$ is the length of control cycle. We will talk each of the cases in details next.
%in order to improve the PPW of the core, it's necessary to improve the temperature, the difference is how much to improve. We assume the operating frequency in the process is fixed, the goal is to improve the PPW during $t$ and $t+h$, and maintain the temperature of $T_{t+h}$ until $t+2h$. $h$ is the length of control cycle.  Therefore, the $3$ senerios with different frequencies can also be classified by the target temperature by $T(t+h)$. For $f_{1}$, $T(t+h)$ will be higher than $T_{opt}$, $f_{2}$ will lead to $T_{opt}$ in $t+h$, and for $f_{3}$, $T_{t+h}$ will be lower than $T_{opt}$. 

We begin with the case where previous temperature is below $T_{opt}$, as Fig.~\ref{fig:ppw_boost_1} shows, for different frequencies, the temperature by the end of the $1^{st}$ control cycle will be different. And in the $2^{nd}$ control cycle, the temperature of all $3$ operating frequencies will remain constant, meaning they are in steady state from $t+h$ to $t+2h$.

Note that although $f_{1}>f_{2}>f_{3}$ is correct for both the control cycles, there is a sudden drop of frequency in $t+h$ for all cases, which comes from the fact that the power budget provided by our method to increase temperature to target temperature is higher than that of the target temperature in steady state. This means our method can provides "performance boost" when previous temperature is lower than target temperature.

Also as shown in Fig.~\ref{fig:ppw_boost_1}, PPW will temporarily increase dramatically in the beginning of the $1^{st}$ control cycle. The reason can be obtained from the definition of PPW as
\begin{equation}\label{eq:ppw_detail}
\text{PPW} = \frac{\left \| f \right \|_{1}}{\left \| P_{d}+P_{s}(T) \right \|_{1}},
\end{equation}
As shown in Fig.~\ref{fig:ppw_boost_1}, $f$ and $P_{d}$ will instantly change, however, $P_{s}$ is only relative to $T$, as the change of $T$ takes time, $P_{s}$ will be lower than its value in steady state for corresponding $f$ in the $1^{st}$ control cycle. Therefore, for the case where previous temperature is below $T_{opt}$, PPW will increase dramatically with the increase of $f$, especially for $f$ equals to or above $f_{2}$, PPW will temporarily exceed the optimal PPW of steady state, which means besides "performance boost", our method can also provides "PPW boost". Due to "performance boost", "PPW boost" is further increased. By the end of the $1^{st}$ control cycle, PPW for all cases will still be higher than that of corresponding temperature in steady state. For $f_{2}$, PPW in the $1^{st}$ control cycle remains higher than $\text{PPW}_{opt}$ in steady state.


%This means, when previous temperature is lower than $T_{opt}$, our method can provide a PPW higher than the $\text{PPW}_{opt}$ in steady state.
% For in the first case, $T(t+h)$ is higher than $T_{opt}$, PPW will gradually decrease, until $t+h$, it will be lower than optimal PPW. 

Then we focus on the case where previous temperature is above $T_{opt}$, as Fig.~\ref{fig:ppw_boost_2} shows, for all $3$ kinds of frequencies, contrary to the first case, to correct the previous over high temperature, we have to suffer from "performance deterioration" and "PPW deterioration". The "performance deterioration" comes from the fact that in order to reach target temperature by the end of the $1^{st}$ control cycle, the power budget given by our method is lower than that of corresponding target temperature in steady state. The reason of "PPW deterioration" is relatively the same as "PPW boost", in that contrary to $f$ and $P_{d}$, the change of $P_{s}$ takes time, therefore $P_{s}$ will be larger than that of steady state in the $1^{st}$ control cycle, resulting in a PPW less than the PPW in steady state. Note that the "performance deterioration" further deteriorate PPW, as by $T(t+h)$, PPW is still lower than that in steady state.
%as there is a boost in PPW at the beginning of $2^{nd}$ control cycle.


For the last case where previous temperature is $T_{opt}$, as Fig.~\ref{fig:ppw_boost_3} shows, for $f_{2}$, the power budget is the same as in steady state, therefore, we focus on the other $2$ scenarios. For $f_{1}$, because the target temperature is higher than $T_{opt}$, there is "PPW boost" in the $1^{st}$ control cycle. For $f_{3}$, it has to suffer from "PPW deterioration" due to lowering temperature.


We next focus on verifying the effectiveness of $T_{opt}$ in transient state, which equals to proving the overall PPW during a control cycle of $f_{2}$ is the highest among $f_{1}$, $f_{2}$ and $f_{3}$. We can see in Fig.~\ref{fig:ppw_boost}, no matter what previous temperature it is, the PPW of $f_{3}$ is always lower than that of $f_{2}$ in a control cycle. As for $f_{1}$, although the PPW of higher operating frequency will be higher than that of $f_{2}$ in the first half of the control cycle, the deviation of the target temperature from $T_{opt}$ makes the PPW of it lower than that of $f_{2}$ in the second half of the control cycle. Overall, the PPW of $f_{1}$ and $f_{2}$ is approximately the same. However, the PPW in the next control cycle is what sets them apart. By remaining the current temperature, the PPW of $f_{1}$ will be lower than that of $f_{2}$. Or, if the temperature is corrected to $T_{opt}$, the PPW will be even worse because of "PPW deterioration" mentioned above. Therefore, the PPW of applying $f_{2}$ in all circumstances will be maximum among $f_{1}$, $f_{2}$ and $f_{3}$.


% In the case where previous temperature is $T_{opt}$, As shown in Fig.~\ref{fig:ppw_boost}, 

% We can see in Fig.~\ref{fig:ppw_1_3}, compared to $f_{2}$, the PPW of $f_{1}$ is higher in the beginning of the control cycle, which is because $f_{1}$ is higher than $f_{2}$, and it takes time for $P_{s}$ to change. Because $T_{t+h}$ of $f_{1}$ is higher than $T_{opt}$, the PPW of $f_{1}$ will decrease faster than the PPW of $f_{2}$, which leads to lower PPW in the second half of the control cycle. For $f_{3}$, because $f_{3}$ is the lowest among all three cases, the PPW is also the lowest in the beginning. And $T(t+h)$ of $f_{3}$ is lower than $T_{opt}$, the PPW in the second half is still lower than the PPW of the second case. 




% by applying three different operating frequencies, $T(t+h)$ and PPW will change accordingly. 

% In the beginning, $f$ and $P_{d}$ change instantly, and the change of $T$ takes time, therefore, $P_{s}$ still remains high, which causes PPW to drop instantly at the beginning of $1^{st}$ control cycle. 



% In the meantime, because the decreasement of $f_{1}$ is less than $f_{2}$, the corresponding PPW drop of $f_{1}$ is also less. Yet the deviation from $T_{opt}$ in $t+h$ causes the PPW of $f_{1}$ in $t+h$ less than optimal PPW. For $f_{3}$, the largest drop in frequency causes the PPW to drop most dramaticly, and the lower temperature in $t+h$ than $T_{opt}$ leads to PPW lower than optimal in then end of the interval.  

% We can see for frequency lower than $f_{2}$, no matter the previous temperature is higher or lower than $T_{opt}$, the PPW in the interval will always be lower than the PPW of $f_{2}$. For frequency higher than $f_{2}$, no matter the previous temperature is higher or lower than $T_{opt}$, compared to the PPW of $f_{2}$, the PPW in the first half of the interval will be higher, and lower in the second half, and overall approximately the same. However, because the $T(t+h)$ is higher than $T_{opt}$, a further adjustment in the next control interval is required, which will will lead to major loss in PPW. Therefore, $T_{opt}$ is still effective in transient state.

With $T_{opt}$ being effective, the basic problem in dynamic power budgeting is to represent temperature rise $T_{c}(t+h)$ using the input power $P$ and initial temperature rise $T_{t}$. Once the formulation of $T_{c}(t+h)$ is available, we can input it into the basic optimization problem \eqref{eq:opt_topt}, and get the sub-optimal $P$ using the similar greedy based method presented in Section $4.3$.

For \eqref{eq:gt}, we can discrete this model using backward Euler's method, and get
\begin{equation}\label{eq:discrete_gt}
(\frac{C}{h}+G)\cdot T(t+h)=\frac{C}{h}T(t)+BP,
\end{equation}
and we are able to express $T_{c}(t+h)$ using $P$ and $T(t)$ as
\begin{equation}\label{eq:discrete_gt}
  \begin{split}
T_{c}(t+h)&=B^{T}T(t+h)\\
&=B^{T}(\frac{C}{h}+G)^{-1}T(h)+B^{T}(\frac{C}{h}+G)^{-1}BP.
  \end{split}
\end{equation}
%\emph{constant}

The cost function of the steady state power budgeting problem in
\eqref{eq:opt_topt} will be changed by using the new $T_c(t+h)$ for
transient case as
\begin{equation}\label{eq:cost_trans}
\|T_{opt} -  B^{T}(\frac{C}{h}+G)^{-1}T(h)+B^{T}(\frac{C}{h}+G)^{-1}BP\|_2.
\end{equation}
In order to simplify notation, we denote a new vector  
\begin{equation}
\bar{T}_{opt}=T_{opt} - B^{T}(\frac{C}{h}+G)^{-1}T(h),
\end{equation}
where $\bar{T}_{opt}$ has similar meaning of
$T_{opt}$ in steady state case, and it also accounts for the transient
thermal effects, i.e., current temperature's impact on power
budget. Also, we denote a new matrix 
\begin{equation}
\bar{A} = B^{T}(\frac{C}{h}+G)^{-1}B, 
\end{equation}
which works similarly as matrix $A$ in steady
state case, but accounts for transient thermal effect. The power
budgeting optimization problem for transient case is updated as 
\begin{equation}\label{eq:temp_ts_opt}
\begin{split}
\text{minimize } &  \left \| \bar{T}_{opt}-\bar{A}P \right \|_{2}\\
\text{subject to} &\left\{
\begin{array}{lr}
\text{card}(P) = n_{a},\\
\bar{A}P \preceq \bar{T}_{th}.\\
\end{array}
\right.
\end{split}
\end{equation}
Now dynamic power budgeting can be
applied by following the steps in steady state power budgeting presented in
Section $4.3$, just with \eqref{eq:sim_opt_topt} replaced
by \eqref{eq:temp_ts_opt}.


